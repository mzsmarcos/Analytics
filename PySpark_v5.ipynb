{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXRtXF+RhRlqm4Iltp0s1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzsmarcos/Analytics/blob/main/PySpark_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do PySpark -  instalar o PySpark no Colab"
      ],
      "metadata": {
        "id": "nigaxeaJkMCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB8LpMTWkLSp",
        "outputId": "19581c96-9f06-4fb8-b978-8c5a901d1149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ],
      "source": [
        "# Instalar o PySpark\n",
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executar a instalação do PySpark e configurar o ambiente Spark.\n",
        "\n",
        "Isso é feito definindo algumas variáveis de ambiente para garantir que o Spark funcione corretamente no Colab."
      ],
      "metadata": {
        "id": "3h6QW5hCk3Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Java 8\n",
        "!apt-get install openjdk-8-jdk -y\n",
        "\n",
        "# Baixar o Apache Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "# Extrair o Apache Spark\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "# Definir variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "# Instalar as bibliotecas PySpark e Findspark\n",
        "!pip install -q pyspark==3.2.1 findspark\n",
        "\n"
      ],
      "metadata": {
        "id": "p9L1Vi5qkrn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ce2a1f-b065-48d0-8810-1b61983e9563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-8-jdk is already the newest version (8u432-ga~us1-0ubuntu2~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se o arquivo foi baixado\n",
        "!ls -lh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6I03-onnFfZ",
        "outputId": "8e444cad-1c4a-4d03-91fe-5a0eaabcc189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 575M\n",
            "drwx------  6 root root 4.0K Feb  5 00:30 drive\n",
            "drwxr-xr-x  1 root root 4.0K Feb  3 14:20 sample_data\n",
            "drwxr-xr-x 13  501 1000 4.0K Jan 20  2022 spark-3.2.1-bin-hadoop3.2\n",
            "-rw-r--r--  1 root root 288M Jan 20  2022 spark-3.2.1-bin-hadoop3.2.tgz\n",
            "-rw-r--r--  1 root root 288M Jan 20  2022 spark-3.2.1-bin-hadoop3.2.tgz.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar a Sessão Spark"
      ],
      "metadata": {
        "id": "DwyHmqlJ7y7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar as bibliotecas\n",
        "import findspark\n",
        "findspark.init(\"/content/spark-3.2.1-bin-hadoop3.2\")\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Criar a sessão Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySparkExample\") \\\n",
        "    .config(\"spark.executor.memory\", \"2g\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Verificar se a sessão foi criada corretamente\n",
        "print(\"Versão do Spark:\", spark.version)\n"
      ],
      "metadata": {
        "id": "6wKpgQX9-uVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8816fa-985f-4731-c36f-ec2e5f73c123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão do Spark: 3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importe das Bibliotecas\n",
        "from pyspark.sql import SparkSession\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "xmt3_Tn6OnG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montando o Google Drive no Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9trpJPzwPO-4",
        "outputId": "fcc89fb7-c723-410d-d2f2-a39e3a4497ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapeando todos os arquivos descompactados"
      ],
      "metadata": {
        "id": "3bhsNxh-uye_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para o diretório\n",
        "directory = '/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/'\n",
        "\n",
        "# Lista todos os arquivos no diretório\n",
        "files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
        "\n",
        "# Imprime o nome de cada arquivo\n",
        "for file in files:\n",
        "    print(file)\n",
        "\n",
        "files.sort()\n",
        "\n",
        "# Imprime o total de arquivos\n",
        "print(f\"Total de arquivos: {len(files)}\")"
      ],
      "metadata": {
        "id": "LD3385poP9G9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29931ed7-9f38-45d6-87a4-071a0811a720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K3241.K03200Y2.D50111.EMPRECSV\n",
            "K3241.K03200Y3.D50111.EMPRECSV\n",
            "K3241.K03200Y4.D50111.EMPRECSV\n",
            "K3241.K03200Y5.D50111.EMPRECSV\n",
            "K3241.K03200Y6.D50111.EMPRECSV\n",
            "K3241.K03200Y7.D50111.EMPRECSV\n",
            "K3241.K03200Y8.D50111.EMPRECSV\n",
            "K3241.K03200Y9.D50111.EMPRECSV\n",
            "K3241.K03200Y0.D50111.ESTABELE\n",
            "K3241.K03200Y1.D50111.ESTABELE\n",
            "K3241.K03200Y2.D50111.ESTABELE\n",
            "K3241.K03200Y3.D50111.ESTABELE\n",
            "K3241.K03200Y4.D50111.ESTABELE\n",
            "K3241.K03200Y5.D50111.ESTABELE\n",
            "K3241.K03200Y6.D50111.ESTABELE\n",
            "K3241.K03200Y7.D50111.ESTABELE\n",
            "K3241.K03200Y8.D50111.ESTABELE\n",
            "K3241.K03200Y9.D50111.ESTABELE\n",
            "F.K03200$Z.D50111.MOTICSV\n",
            "F.K03200$Z.D50111.MUNICCSV\n",
            "F.K03200$Z.D50111.NATJUCSV\n",
            "F.K03200$Z.D50111.PAISCSV\n",
            "F.K03200$Z.D50111.QUALSCSV\n",
            "F.K03200$W.SIMPLES.CSV.D50111\n",
            "K3241.K03200Y0.D50111.SOCIOCSV\n",
            "K3241.K03200Y1.D50111.SOCIOCSV\n",
            "K3241.K03200Y2.D50111.SOCIOCSV\n",
            "K3241.K03200Y3.D50111.SOCIOCSV\n",
            "K3241.K03200Y4.D50111.SOCIOCSV\n",
            "K3241.K03200Y5.D50111.SOCIOCSV\n",
            "K3241.K03200Y6.D50111.SOCIOCSV\n",
            "K3241.K03200Y7.D50111.SOCIOCSV\n",
            "K3241.K03200Y8.D50111.SOCIOCSV\n",
            "K3241.K03200Y9.D50111.SOCIOCSV\n",
            "F.K03200$Z.D50111.CNAECSV\n",
            "K3241.K03200Y0.D50111.EMPRECSV\n",
            "K3241.K03200Y1.D50111.EMPRECSV\n",
            "Total de arquivos: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "import os\n",
        "\n",
        "# Caminho para o diretório\n",
        "directory = '/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/'\n",
        "\n",
        "# Constrói o caminho completo para o arquivo\n",
        "file_path = os.path.join(directory, 'F.K03200$Z.D50111.CNAECSV')\n",
        "\n",
        "# Lê o arquivo CSV sem definir nomes de colunas, mas garantindo que todas as colunas sejam StringType\n",
        "df_cnae = (spark.read\n",
        "    .option(\"charset\", \"latin1\")  # Define o encoding correto\n",
        "    .option(\"quote\", \"\\\"\")  # Mantém texto entre aspas duplas\n",
        "    .option(\"delimiter\", \";\")  # Define o separador correto\n",
        "    .option(\"inferSchema\", \"false\")  # Não inferir automaticamente os tipos de dados\n",
        "    .csv(file_path)  # Ler o arquivo, assumindo que a primeira linha é o cabeçalho\n",
        ")\n",
        "\n",
        "# Exibe as primeiras linhas para conferência\n",
        "df_cnae.show()\n",
        "\n",
        "# Exibe o schema inferido (todas as colunas devem ser StringType)\n",
        "df_cnae.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9BdDq8J844g",
        "outputId": "fb7c85b4-3a58-4e43-c45e-46bc220613d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|    _c0|                 _c1|\n",
            "+-------+--------------------+\n",
            "|0111301|    Cultivo de arroz|\n",
            "|0111302|    Cultivo de milho|\n",
            "|0111303|    Cultivo de trigo|\n",
            "|0111399|Cultivo de outros...|\n",
            "|0112101|Cultivo de algodã...|\n",
            "|0112102|     Cultivo de juta|\n",
            "|0112199|Cultivo de outras...|\n",
            "|0113000|Cultivo de cana-d...|\n",
            "|0114800|     Cultivo de fumo|\n",
            "|0115600|     Cultivo de soja|\n",
            "|0116401| Cultivo de amendoim|\n",
            "|0116402| Cultivo de girassol|\n",
            "|0116403|   Cultivo de mamona|\n",
            "|0116499|Cultivo de outras...|\n",
            "|0119901|  Cultivo de abacaxi|\n",
            "|0119902|     Cultivo de alho|\n",
            "|0119903|Cultivo de batata...|\n",
            "|0119904|   Cultivo de cebola|\n",
            "|0119905|   Cultivo de feijão|\n",
            "|0119906| Cultivo de mandioca|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lendo e tratando o arquivo Cnae"
      ],
      "metadata": {
        "id": "4NzxHe-7iKO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtém o número de linhas\n",
        "num_linhas = df_cnae.count()\n",
        "\n",
        "# Obtém o número de colunas\n",
        "num_colunas = len(df_cnae.columns)\n",
        "\n",
        "print(f\"Número de linhas: {num_linhas}\")\n",
        "print(f\"Número de colunas: {num_colunas}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU4CS6E_iOuk",
        "outputId": "250eb43f-eb47-4905-b782-55d4db68fd21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de linhas: 1359\n",
            "Número de colunas: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação de valores nulos\n",
        "\n",
        "from pyspark.sql.functions import col, count, when\n",
        "\n",
        "for column_name in df_cnae.columns:\n",
        "    null_count = df_cnae.filter(col(column_name).isNull()).count()\n",
        "    print(f\"Coluna: {column_name}, Valores Nulos: {null_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEElbCs_iOxL",
        "outputId": "7834b08a-64cb-411e-ea7e-970a7aa2b18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coluna: _c0, Valores Nulos: 0\n",
            "Coluna: _c1, Valores Nulos: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação de valores duplicados\n",
        "\n",
        "df_cnae.groupBy(df_cnae.columns).count().filter(count(\"*\") > 1).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jZ3aj0Pu6xR",
        "outputId": "4b6a261e-6a0d-4e0c-d584-4f7cd1463d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Incluindo o cabeçalho\n",
        "\n",
        "df_cnae = df_cnae.withColumnRenamed(\"_c0\", \"Cnae\").withColumnRenamed(\"_c1\", \"Descricao\")\n",
        "\n",
        "# Exibe as primeiras linhas para conferir\n",
        "df_cnae.show()\n",
        "\n",
        "# Verifica o schema atualizado\n",
        "df_cnae.printSchema()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqzGkNDxu67p",
        "outputId": "545a785e-4fca-49ca-f1f7-c5891679d084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|   Cnae|           Descricao|\n",
            "+-------+--------------------+\n",
            "|0111301|    Cultivo de arroz|\n",
            "|0111302|    Cultivo de milho|\n",
            "|0111303|    Cultivo de trigo|\n",
            "|0111399|Cultivo de outros...|\n",
            "|0112101|Cultivo de algodã...|\n",
            "|0112102|     Cultivo de juta|\n",
            "|0112199|Cultivo de outras...|\n",
            "|0113000|Cultivo de cana-d...|\n",
            "|0114800|     Cultivo de fumo|\n",
            "|0115600|     Cultivo de soja|\n",
            "|0116401| Cultivo de amendoim|\n",
            "|0116402| Cultivo de girassol|\n",
            "|0116403|   Cultivo de mamona|\n",
            "|0116499|Cultivo de outras...|\n",
            "|0119901|  Cultivo de abacaxi|\n",
            "|0119902|     Cultivo de alho|\n",
            "|0119903|Cultivo de batata...|\n",
            "|0119904|   Cultivo de cebola|\n",
            "|0119905|   Cultivo de feijão|\n",
            "|0119906| Cultivo de mandioca|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- Cnae: string (nullable = true)\n",
            " |-- Descricao: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-bX6l0s1_vj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lendo e tratando os arquivos de Empresas"
      ],
      "metadata": {
        "id": "sK1vFaHI_v_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo todos os equivos de empresas\n",
        "from pyspark.sql.types import StringType\n",
        "import os\n",
        "\n",
        "# Caminho para o diretório\n",
        "directory = '/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/'\n",
        "\n",
        "# Lista com os nomes dos arquivos de empresas\n",
        "empresas_files = [\n",
        "    \"K3241.K03200Y2.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y3.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y4.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y5.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y6.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y7.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y8.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y9.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y0.D50111.EMPRECSV\",\n",
        "    \"K3241.K03200Y1.D50111.EMPRECSV\"\n",
        "]\n",
        "\n",
        "# Criando a lista de caminhos completos para cada arquivo\n",
        "file_paths = [os.path.join(directory, f) for f in empresas_files]\n",
        "\n",
        "# Lendo todos os arquivos de empresas ao mesmo tempo\n",
        "df_empresas = (spark.read\n",
        "    .option(\"charset\", \"latin1\")  # Define o encoding correto\n",
        "    .option(\"quote\", \"\\\"\")  # Mantém texto entre aspas duplas\n",
        "    .option(\"delimiter\", \";\")  # Define o separador correto\n",
        "    .option(\"inferSchema\", \"false\")  # Não inferir automaticamente os tipos de dados\n",
        "    .csv(file_paths)  # Lê todos os arquivos de uma vez\n",
        ")\n",
        "\n",
        "# Exibe as primeiras linhas para conferência\n",
        "df_empresas.show()\n",
        "\n",
        "# Exibe o schema inferido (todas as colunas devem ser StringType)\n",
        "df_empresas.printSchema()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIMA_abwiOzv",
        "outputId": "ee6c23ee-a31f-4d1a-8d61-2fa89d4d3fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+----+---+---------+---+----+\n",
            "|     _c0|                 _c1| _c2|_c3|      _c4|_c5| _c6|\n",
            "+--------+--------------------+----+---+---------+---+----+\n",
            "|04631961|ITACAMP INDUSTRIA...|2062| 49|     0,00| 01|null|\n",
            "|04631962|CLINICA OFTALMOLO...|2062| 49|     0,00| 05|null|\n",
            "|04631963| EXPRESSO COSTA LTDA|2062| 49|     0,00| 01|null|\n",
            "|04631964|PAULO BRAGA PROJE...|2232| 49| 20000,00| 01|null|\n",
            "|04631965|COTERMAQ CONSERTO...|2062| 49|     0,00| 03|null|\n",
            "|04631967|ACACIA MEDICINA D...|2240| 49|500000,00| 03|null|\n",
            "|04631968|CONDOMINIO DO EDI...|3085| 19|     0,00| 05|null|\n",
            "|04631969|      J LEILOES LTDA|2062| 49|     0,00| 05|null|\n",
            "|04631970|J. NOGUEIRA DE QU...|2135| 50|     0,00| 01|null|\n",
            "|04631971|  2001 HANDLING LTDA|2240| 49|     0,00| 01|null|\n",
            "|04631972|GONCALVES E VIANA...|2062| 49|     0,00| 01|null|\n",
            "|04631973|ARCA DO LOUVOR MU...|2062| 49|     0,00| 01|null|\n",
            "|04631975| NELSON DURVAL RISSE|2135| 50|     0,00| 05|null|\n",
            "|04631976|FUNILARIA NOETZOL...|2062| 49|     0,00| 01|null|\n",
            "|04631977|CEP PREVENCAO ODO...|2240| 49| 90000,00| 01|null|\n",
            "|04631978|ESPACO SERVICOS C...|2240| 49|100000,00| 03|null|\n",
            "|04631979|DIVINO ETERNO FER...|2135| 50|     0,00| 01|null|\n",
            "|04631980|MARIA DAS DORES S...|2135| 50|     0,00| 05|null|\n",
            "|04631981|E & M COMERCIO E ...|2062| 49|     0,00| 01|null|\n",
            "|04631983|FERNANDO RODRIGUE...|2135| 50|     0,00| 05|null|\n",
            "+--------+--------------------+----+---+---------+---+----+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            " |-- _c2: string (nullable = true)\n",
            " |-- _c3: string (nullable = true)\n",
            " |-- _c4: string (nullable = true)\n",
            " |-- _c5: string (nullable = true)\n",
            " |-- _c6: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem das linhas\n",
        "\n",
        "df_empresas.take(1)  # Força a execução antes do count\n",
        "num_linhas = df_empresas.count()\n",
        "print(\"Linhas :\", {num_linhas})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb7vVLjRC4dH",
        "outputId": "2c772ab5-9cec-4344-bf0e-e98fe94bfb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linhas : {56465072}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lê a quantidade de linhas por arquivo\n",
        "from pyspark.sql.functions import input_file_name\n",
        "\n",
        "df_empresas.withColumn(\"arquivo\", input_file_name()).groupBy(\"arquivo\").count().show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4IcKVrHC4fz",
        "outputId": "5fd50f42-63bc-4701-f8c9-270e88164217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------+--------+\n",
            "|arquivo                                                                                                          |count   |\n",
            "+-----------------------------------------------------------------------------------------------------------------+--------+\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y2.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y3.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y4.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y5.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y6.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y7.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y8.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y9.D50111.EMPRECSV|4494860 |\n",
            "|file:///content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/descompactados/K3241.K03200Y0.D50111.EMPRECSV|20506192|\n",
            "+-----------------------------------------------------------------------------------------------------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiLOGlJIC4ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dpMjUXF3C4ll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}